import torch
from torch.utils.data import Dataset, DataLoader
import os
import numpy as np
from glob import glob
from utils.utils import *
import pandas as pd
import cv2
import math
import random
from train import init_config


class CUB5000(Dataset):
    '''
        The dataset contains the 5000 image pairs generated by Warpnet (CVPR16)
    '''
    def __init__(self, args, transform=None):
        img_ids = os.path.join(args.data_path, 'images.txt')
        part_locs = os.path.join(args.part_path, 'part_locs.txt')
        pair_ids = os.path.join(args.pair_path, '5000pair_gt7.csv')
        bbox = os.path.join(args.data_path, 'bounding_boxes.txt')

        self.img_folder = args.img_path
        self.imgs = pd.read_csv(img_ids, ' ', header=None, names=['id', 'path'])
        self.img_dict = dict(zip(list(self.imgs.id), list(self.imgs.path)))
        self.parts = pd.read_csv(part_locs, ' ', header=None, names=['iid', 'pid', 'x', 'y', 'vis'])
        self.part_dict = dict(
            zip(list(zip(self.parts.iid, self.parts.pid)), list(zip(self.parts.x, self.parts.y, self.parts.vis))))
        self.pairs = pd.read_csv(pair_ids, ',', header=None, dtype=np.int, names=['id1', 'id2'])

        bboxes = pd.read_csv(bbox, ' ', header=None, names=['id', 'x', 'y', 'width', 'height'])
        self.bbox_dict = dict(
            zip(list(bboxes.id), list(zip(bboxes.x, bboxes.y, bboxes.width, bboxes.height))))

        self.new_H = args.new_H
        self.new_W = args.new_W

        self.transform = transform
        self.max_parts = args.max_parts

    def __len__(self):
        return len(self.pairs)

    def bbox_and_resize_(self, iid, img):
        (x_box, y_box, width_box, height_box) = self.bbox_dict[iid]
        x_box = int(x_box)
        y_box = int(y_box)
        width_box = int(width_box)
        height_box = int(height_box)
        new_img = img[y_box:y_box + height_box, x_box:x_box + width_box, :]
        ratio_H = self.new_H / height_box
        ratio_W = self.new_W / width_box
        new_img = cv2.resize(new_img, (self.new_W, self.new_H))
        return new_img, ratio_H, ratio_W, x_box, y_box

    def __getitem__(self, index):
        iid1, iid2 = self.pairs.iloc[index, :]
        img_path1 = os.path.join(self.img_folder, self.img_dict[iid1])
        img_path2 = os.path.join(self.img_folder, self.img_dict[iid2])
        img1 = cv2.imread(img_path1)/255.
        img2 = cv2.imread(img_path2)/255.

        img1, ratio_H1, ratio_W1, x_box1, y_box1 = self.bbox_and_resize_(iid1, img1)
        img2, ratio_H2, ratio_W2, x_box2, y_box2 = self.bbox_and_resize_(iid2, img2)

        # find visible parts (points) in image1 that have correspondences in image2.
        P1 = []
        gt_P1 = []  # ground truth coordinates of the corresponding parts in image2
        # msk1 = np.zeros_like(img1)
        for ip in range(1, 16):  # maximum number of points is 15
            (x1, y1, vis1) = self.part_dict[(iid1, ip)]
            (x2, y2, vis2) = self.part_dict[(iid2, ip)]
            # if the ip_th part is visible in both image1 and image2
            if vis1 == 1 and vis2 == 1:
                x1 = (x1 - x_box1) * ratio_W1
                y1 = (y1 - y_box1) * ratio_H1
                x2 = (x2 - x_box2) * ratio_W2
                y2 = (y2 - y_box2) * ratio_H2

                P1.append((int(x1), int(y1)))
                gt_P1.append((int(x2), int(y2)))
                # msk1[int(x), int(y)] = 1

        if self.transform:
            img1 = self.transform(img1)
            img2 = self.transform(img2)

        P1 = torch.tensor(P1)
        gt_P1 = torch.tensor(gt_P1)
        np1 = P1.shape[0]
        idx = random.sample(list(range(np1)), self.max_parts)
        P1 = P1[idx, :]
        gt_P1 = gt_P1[idx, :]

        return img1, img2, P1, gt_P1, img_path1, img_path2



class CUB5000_perm(CUB5000):
    '''
     - The dataset contains the 5000 image pairs generated by Warpnet (CVPR16)
     - The parts in the target image (image 2) form a permutation of the ground truth parts
    '''
    def __init__(self, args, transform=None):
        # param np2_grid: resolution of the grid for sampling points in image 2, so np2_grid^2 points are sampled.
        super(CUB5000_perm, self).__init__(args, transform)
        # self.perm_idx = np.random.permutation(args.max_parts)

    def __getitem__(self, index):
        img1, img2, P1, gt_P1, img_path1, img_path2 = super(CUB5000_perm, self).__getitem__(index)
        np1 = gt_P1.size()[0]
        idx = np.random.permutation(np1)
        P2 = gt_P1[idx, :]
        return img1, img2, P1, gt_P1, img_path1, img_path2, P2




class UnNormalize(object):
    def __init__(self, mean, std):
        self.mean = mean
        self.std = std

    def __call__(self, tensor):
        for t, m, s in zip(tensor, self.mean, self.std):
            t.mul_(s).add_(m)
            # The normalize code -> t.sub_(m).div_(s)
        return tensor






